---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "100%"
)

options(tibble.print_min = 5, tibble.print_max = 5)

set.seed(27)
```

# safepredict
[![Travis build status](https://travis-ci.org/alexpghayes/safepredict.svg?branch=master)](https://travis-ci.org/alexpghayes/safepredict)
[![Coverage status](https://codecov.io/gh/alexpghayes/safepredict/branch/master/graph/badge.svg)](https://codecov.io/github/alexpghayes/safepredict?branch=master)
[![lifecycle](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)


The goal of safepredict is to provide consistent predictions via the `safe_predict()` generic. `safe_predict()`:

- always returns a tibble.
- never drops rows with missing data.
- follows a consistent naming convention.

The goal is to eventually meet the full [tidymodels prediction specification][pred_spec].

[pred_spec]: https://tidymodels.github.io/model-implementation-principles/model-predictions.html

## Before you get started

it's possible you are trying to solve a problem that's already been solved. go checkout [`parsnip`](https://tidymodels.github.io/parsnip/).

## Installation

`safepredict` is currently in the beginning stages of development and is available only on Github. You can install it with:

```r
# install.packages("devtools")
devtools::install_github("alexpghayes/safepredict")
```

## Conventions

Arguments:

- `object`
- `new_data` not data. *required*, you will get an error otherwise. The data requirements for `new_data` should be the same as those for the orginal model fit function. 
- `type`

    | type         	| application                                 	|
    |--------------	|---------------------------------------------	|
    | `response`   	| numeric predictions                         	|
    | `class`      	| hard class predictions                      	|
    | `prob`       	| class probabilities, survivor probabilities 	|
    | `link`       	| `glm` linear predictor                      	|
    | `conf_int`   	| confidence intervals                        	|
    | `pred_int`   	| prediction intervals                        	|
    | `raw`        	| direct access to prediction function        	|
    | `param_pred` 	| predictions across tuning parameters        	|
    | `quantile`    | quantile predictions                          |
    
  
    This is validated using `rlang::arg_match()` to prevent silent errors.
  
- `level`
- `std_error` argument that takes on `TRUE/FALSE` value. By default, do not report standard error or other measures of uncertainty, as these can be expensive to compute. Clearly document whether any standard errors are for confidence or prediction intervals.

## Features

- clear documentation about when you're getting confidence vs prediction intervals
- always a pointer to a method that will let you assess uncertainty in your prediction if prediction intervals are not available
- always preserves missing data, or errors out informatively

- won't explode if you:

  - have a single row
  - have lots of rows
  
- full support of splines (i.e. doesn't get caught in the splines trap)

## Things that are hard to fully support

- When novel factor levels appear in the test set for factor predictors, the default behavior should be to throw an informative error. For models where this is a reasonable way to make predictions on novel factor levels, users need to explicitly specify that they want this behavior, and it's good practice to `message()` for these prediction cases.

- Predictions on same scale as outcome, of same type (i.e. factor / numeric)

## Return Values

- The return value is a tibble with the **same number of rows as the data being predicted** and in the same order. 

- Interval attributes

- Missing data always specified as `NA` (i.e. never `Inf` or `NaN`) -- write a test for this

Columns naming:


   * For univariate, numeric point estimates, the column should be named `.pred`. For multivariate numeric predictions (excluding probabilities), the columns should be named `.pred_{outcome name}`.
      
   * Class predictions should be factors with the same levels as the original outcome and named `.pred_class`. 
   
   * For class probability predictions, the columns should be named the same as the factor levels, e.g., `.pred_{level}`, and there should be as many columns as factor levels. 
 
   * If interval estimates are produced (e.g. prediction/confidence/credible), the column names should be `.pred_lower` and `.pred_upper`. If a standard error is produced, the column should be named `.std_error`. If intervals are produced for class probabilities, the levels should be included (e.g., `.pred_lower_{level}`)

## Examples

Suppose you fit a logistic regression using `glm`:

```{r}
library(tibble)

data <- tibble(
  y = as.factor(rep(c("A", "B"), each = 50)),
  x = c(rnorm(50, 1), rnorm(50, 3))
)

fit <- glm(y ~ x, data, family = binomial)
```

Errors are caught: **TODO**: Use `ellipsis` to prevent `conf.level` errors

```{r}

```

You can predict class probabilities:

```{r}
library(safepredict)

test <- tibble(x = rnorm(10, 2))

safe_predict(fit, new_data = test, type = "prob")
```

or can jump straight to hard class decisions

```{r}
safe_predict(fit, new_data = test, type = "class")
```

We can also get predictions on the link scale:


```{r}
safe_predict(fit, new_data = test, type = "link")
```

or we can get confidence intervals on the response scale

```{r}
safe_predict(fit, new_data = test, type = "conf_int")
```
